"""
åŸºäºæ‰‹åŠ¿è¯†åˆ«çš„æ™ºèƒ½å›¾åƒæ»¤é•œåˆ‡æ¢ç³»ç»Ÿ
ä¸»å…¥å£ç¨‹åº

åŠŸèƒ½ï¼š
- å®æ—¶è§†é¢‘æµä¸­è¯†åˆ«æ‰‹åŠ¿ï¼Œæ ¹æ®æ‰‹åŠ¿åˆ‡æ¢å›¾åƒæ»¤é•œï¼Œå¹¶æ”¯æŒæ‹ç…§åŠŸèƒ½ã€‚
- æ”¯æŒæ¼”ç¤ºæ¨¡å¼ï¼Œå±•ç¤ºæ‰€æœ‰æ»¤é•œæ•ˆæœã€‚
- æ”¯æŒå›¾ç‰‡å¤„ç†æ¨¡å¼ï¼Œå¯¹æŒ‡å®šå›¾ç‰‡åº”ç”¨æ»¤é•œã€‚
æ‰‹åŠ¿æ˜ å°„å…³ç³»:
- ONE (1) -> ç›´æ–¹å›¾å‡è¡¡åŒ–
- TWO (2) -> æµå¹´ç‰¹æ•ˆ
- THREE (3) -> ç°åº¦ç‰¹æ•ˆ
- FOUR (4) -> æ€€æ—§ç‰¹æ•ˆ
"""

import cv2
import sys
import os
import time
import argparse

# # æ·»åŠ  utils è·¯å¾„
# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'utils'))

from utils.gesturedetector import HandDetector
from utils.imagefilter import ImageFilter, FilterController, add_filter_info_overlay


class GestureFilterSystem:
    """åŸºäºæ‰‹åŠ¿è¯†åˆ«çš„å›¾åƒæ»¤é•œç³»ç»Ÿ"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç³»ç»Ÿ"""
        self.hand_detector = HandDetector()
        self.image_filter = ImageFilter()
        self.filter_controller = FilterController()
        self.current_gesture = "NO HAND"
        self.current_filter = "original"
        self.last_filter_gesture = None  # ä¸Šä¸€æ¬¡æ”¹å˜æ»¤é•œçš„æ‰‹åŠ¿
        self.p_time = 0
        self.frame_count = 0
        
        # æ‹ç…§åŠŸèƒ½ç›¸å…³
        self.gesture_sequence = []  # è®°å½•æ‰‹åŠ¿åºåˆ—
        self.sequence_timeout = 0.5  # æ‰‹åŠ¿åºåˆ—è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        self.last_gesture_time = 0
        
        # å»¶è¿Ÿæ‹ç…§ç›¸å…³
        self.photo_triggered = False  # æ˜¯å¦è§¦å‘äº†æ‹ç…§
        self.photo_trigger_time = 0  # è§¦å‘æ‹ç…§çš„æ—¶é—´
        self.photo_delay = 2.0  # æ‹ç…§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        
        # ä¿å­˜æ— UIçš„å¹²å‡€ç‰ˆæœ¬
        self.clean_frame = None  # ä¿å­˜æœ€åä¸€å¸§çš„æ— UIç‰ˆæœ¬
        
        print("="*60)
        print("åŸºäºæ‰‹åŠ¿è¯†åˆ«çš„æ™ºèƒ½å›¾åƒæ»¤é•œåˆ‡æ¢ç³»ç»Ÿ")
        print("="*60)
        print("\næ‰‹åŠ¿æ˜ å°„å…³ç³»:")
        print("  ONE   (1)  â†’ ç›´æ–¹å›¾å‡è¡¡åŒ–")
        print("  TWO   (2)  â†’ æµå¹´ç‰¹æ•ˆ")
        print("  THREE (3)  â†’ ç°åº¦ç‰¹æ•ˆ")
        print("  FOUR  (4)  â†’ æ€€æ—§ç‰¹æ•ˆ")
        print("\nå…¶ä»–æ‰‹åŠ¿:")
        print("  FIST  â†’ ä¸æ”¹å˜æ»¤é•œ")
        print("  PALM  â†’ ä¸æ”¹å˜æ»¤é•œ")
        print("  ä¸¤åªæ‰‹åŒæ—¶å‡ºç° â†’ å–æ¶ˆæ»¤é•œï¼ˆå˜ä¸ºåŸå›¾ï¼‰")
        print("\nç‰¹æ®ŠåŠŸèƒ½:")
        print("  PALM â†’ FIST â†’ å»¶è¿Ÿ2ç§’åæ‹ç…§ä¿å­˜")
        print("\næ§åˆ¶æŒ‰é”®:")
        print("  Q/ESC â†’ é€€å‡º")
        print("="*60 + "\n")
    
    def process_frame(self, frame):
        """å¤„ç†å•å¸§å›¾åƒ"""
        # 1. æ‰‹åŠ¿æ£€æµ‹
        frame = self.hand_detector.find_hands(frame, draw=True)
        self.current_gesture = self.hand_detector.get_gesture(frame)
        
        # 2. å¦‚æœæ£€æµ‹åˆ°ä¸¤åªæ‰‹ï¼Œå–æ¶ˆæ»¤é•œï¼Œä½¿ç”¨åŸå›¾
        if self.current_gesture == "TWO_HANDS":
            self.current_filter = "original"
            self.last_filter_gesture = None
        # 3. åªæœ‰åœ¨åšå‡ºæ•°å­—æ‰‹åŠ¿ï¼ˆONE/TWO/THREE/FOURï¼‰æ—¶æ‰æ”¹å˜æ»¤é•œ
        elif self.current_gesture in ["ONE", "TWO", "THREE", "FOUR"]:
            # æ£€æµ‹åˆ°æ–°çš„æ•°å­—æ‰‹åŠ¿ï¼ˆä¸ä¸Šä¸€æ¬¡æ”¹å˜çš„æ‰‹åŠ¿ä¸åŒï¼‰
            if self.last_filter_gesture != self.current_gesture:
                self.last_filter_gesture = self.current_gesture
                self.current_filter = self.filter_controller.update_by_gesture(self.current_gesture)
        
        # 4. æ£€æµ‹æ‹ç…§æ‰‹åŠ¿åºåˆ— (PALM -> FIST)
        should_trigger_photo = self._check_photo_gesture_sequence()
        if should_trigger_photo:
            self.photo_triggered = True
            self.photo_trigger_time = time.time()
        
        # 5. æ£€æŸ¥å»¶è¿Ÿæ‹ç…§æ˜¯å¦åˆ°è¾¾
        should_take_photo = False
        if self.photo_triggered:
            elapsed = time.time() - self.photo_trigger_time
            if elapsed >= self.photo_delay:
                should_take_photo = True
                self.photo_triggered = False
        
        # 6. åº”ç”¨æ»¤é•œ
        processed_frame = self.image_filter.apply_filter(frame.copy(), self.current_filter)
        
        # 7. ä¿å­˜æ— UIç‰ˆæœ¬ç”¨äºæ‹ç…§
        self.clean_frame = processed_frame.copy()
        
        # 8. æ·»åŠ ä¿¡æ¯å åŠ å±‚ï¼ˆä»…ç”¨äºæ˜¾ç¤ºï¼‰
        display_frame = self._add_ui_overlay(processed_frame.copy())
        
        # 9. å¦‚æœæ‹ç…§æ—¶é—´åˆ°è¾¾ï¼Œåˆ™æ‹ç…§ï¼ˆä½¿ç”¨æ— UIç‰ˆæœ¬ï¼‰
        if should_take_photo:
            self.save_frame(self.clean_frame, is_photo=True)
        
        return display_frame
    
    def _check_photo_gesture_sequence(self):
        """æ£€æµ‹æ‹ç…§æ‰‹åŠ¿åºåˆ— (PALM -> FIST)"""
        current_time = time.time()
        
        # æ¸…ç†è¿‡æœŸçš„æ‰‹åŠ¿è®°å½•
        if self.gesture_sequence and (current_time - self.last_gesture_time) > self.sequence_timeout:
            self.gesture_sequence = []
        
        # å¦‚æœæ‰‹åŠ¿å‘ç”Ÿå˜åŒ–ï¼Œè®°å½•æ–°æ‰‹åŠ¿
        if self.current_gesture != "NO HAND":
            if not self.gesture_sequence or self.gesture_sequence[-1] != self.current_gesture:
                self.gesture_sequence.append(self.current_gesture)
                self.last_gesture_time = current_time
        
        # æ£€æµ‹ PALM -> FIST åºåˆ—
        if len(self.gesture_sequence) >= 2:
            if self.gesture_sequence[-2] == "PALM" and self.gesture_sequence[-1] == "FIST":
                self.gesture_sequence = []  # æ¸…ç©ºåºåˆ—
                return True
        
        return False
    
    def _add_ui_overlay(self, frame):
        """æ·»åŠ UIä¿¡æ¯å åŠ å±‚"""
        h, w = frame.shape[:2]
        
        # ä¸Šæ–¹ä¿¡æ¯æ¡† - æ‰‹åŠ¿å’Œæ»¤é•œåç§°
        overlay = frame.copy()
        overlay_height = 90 if self.photo_triggered else 70
        cv2.rectangle(overlay, (0, 0), (w, overlay_height), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)
        
        # æ‰‹åŠ¿ä¿¡æ¯
        gesture_color = (0, 255, 0) if self.current_gesture != "NO HAND" else (0, 0, 255)
        
        # åŒºåˆ†ä¸åŒæ‰‹åŠ¿ç±»å‹çš„æ˜¾ç¤º
        if self.current_gesture == "TWO_HANDS":
            gesture_text = f'Gesture: {self.current_gesture} (Filter Cancelled)'
        elif self.current_gesture in ["ONE", "TWO", "THREE", "FOUR"]:
            gesture_text = f'Gesture: {self.current_gesture} (Filter Changed)'
        else:
            gesture_text = f'Gesture: {self.current_gesture}'
        
        cv2.putText(frame, gesture_text, (10, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, gesture_color, 2)
        
        # æ»¤é•œåç§° - æ˜¾ç¤ºå½“å‰æŒä¹…åŒ–çš„æ»¤é•œ
        cv2.putText(frame, f'Current Filter: {self.current_filter}', (10, 50),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # æ‹ç…§å€’è®¡æ—¶
        if self.photo_triggered:
            elapsed = time.time() - self.photo_trigger_time
            countdown = max(0, self.photo_delay - elapsed)
            countdown_text = f'Photo in {countdown:.1f}s'
            cv2.putText(frame, countdown_text, (10, 75),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
        
        # FPS æ˜¾ç¤º
        c_time = time.time()
        fps = 1 / (c_time - self.p_time) if (c_time - self.p_time) > 0 else 0
        self.p_time = c_time
        cv2.putText(frame, f'FPS: {int(fps)}', (w - 150, 25),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        # å¸§æ•°æ˜¾ç¤º
        self.frame_count += 1
        cv2.putText(frame, f'Frame: {self.frame_count}', (w - 150, 55),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        # ä¸‹æ–¹å¸®åŠ©ä¿¡æ¯
        help_text = "Q:Quit | Space:Save | PALM+FIST:Photo(2s delay) | 2Hands:Cancel Filter"
        cv2.putText(frame, help_text, (15, h - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
        
        return frame
    
    def save_frame(self, frame, is_photo=False):
        """ä¿å­˜å½“å‰å¸§åˆ°æ–‡ä»¶"""
        output_dir = "./data/output"
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        prefix = "photo" if is_photo else "screenshot"
        filename = f"{output_dir}/{prefix}_{timestamp}_{self.current_filter}.jpg"
        
        cv2.imwrite(filename, frame)
        
        if is_photo:
            print(f"ğŸ“· æ‹ç…§å·²ä¿å­˜: {filename}")
        else:
            print(f"âœ“ å·²ä¿å­˜: {filename}")
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        cap = cv2.VideoCapture(0)
        
        if not cap.isOpened():
            print("âœ— é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´")
            return
        
        print("âœ“ æ‘„åƒå¤´å·²æ‰“å¼€ï¼Œç³»ç»Ÿå¼€å§‹è¿è¡Œ...\n")
        
        window_name = "Gesture-based Image Filter System"
        
        try:
            while True:
                success, frame = cap.read()
                
                if not success:
                    print("âœ— æ— æ³•è¯»å–æ‘„åƒå¤´")
                    break
                
                # é•œåƒç¿»è½¬
                frame = cv2.flip(frame, 1)
                
                # å¤„ç†å¸§
                display_frame = self.process_frame(frame)
                
                # æ˜¾ç¤º
                cv2.imshow(window_name, display_frame)
                
                # å¤„ç†æŒ‰é”®
                key = cv2.waitKey(1) & 0xFF
                
                if key == ord('q') or key == 27:  # Q æˆ– ESC
                    print("\nâœ“ ç”¨æˆ·é€€å‡ºç¨‹åº")
                    break
                elif key == ord(' '):  # ç©ºæ ¼é”®ä¿å­˜å½“å‰å¸§
                    self.save_frame(self.clean_frame, is_photo=False)
        
        except KeyboardInterrupt:
            print("\nâœ“ å·²è¢«ä¸­æ–­")
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print("âœ“ ç³»ç»Ÿå…³é—­")


def run_demo_mode():
    """æ¼”ç¤ºæ¨¡å¼ï¼šä½¿ç”¨æµ‹è¯•å›¾ç‰‡"""
    print("\nè¿›å…¥æ¼”ç¤ºæ¨¡å¼...")
    test_image_path = "./data/input/apple.png"
    
    if not os.path.exists(test_image_path):
        print(f"âœ— æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨: {test_image_path}")
        return
    
    frame = cv2.imread(test_image_path)
    
    # åˆ›å»ºç³»ç»Ÿ
    system = GestureFilterSystem()
    
    # æ˜¾ç¤ºæ¯ä¸ªæ»¤é•œæ•ˆæœ
    filter_names = system.image_filter.get_filter_names()
    
    print(f"\nå±•ç¤ºæ‰€æœ‰ {len(filter_names)} ç§æ»¤é•œæ•ˆæœ:\n")
    
    for filter_name in filter_names:
        # åº”ç”¨æ»¤é•œ
        result = system.image_filter.apply_filter(frame.copy(), filter_name)
        
        # æ·»åŠ æ–‡å­—
        h, w = result.shape[:2]
        overlay = result.copy()
        cv2.rectangle(overlay, (0, 0), (w, 60), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.3, result, 0.7, 0, result)
        
        cv2.putText(result, f'Filter: {filter_name}', (15, 35),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # æ˜¾ç¤º
        cv2.imshow("Gesture-based Image Filter System - Demo Mode", result)
        
        print(f"  {filter_name:20} (æŒ‰ä»»æ„é”®æŸ¥çœ‹ä¸‹ä¸€ä¸ªæ»¤é•œ...)")
        cv2.waitKey(0)
    
    cv2.destroyAllWindows()
    print("\nâœ“ æ¼”ç¤ºå®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åŸºäºæ‰‹åŠ¿è¯†åˆ«çš„æ™ºèƒ½å›¾åƒæ»¤é•œåˆ‡æ¢ç³»ç»Ÿ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    
    parser.add_argument("--demo", action="store_true", 
                       help="è¿è¡Œæ¼”ç¤ºæ¨¡å¼ (æ˜¾ç¤ºæ‰€æœ‰æ»¤é•œæ•ˆæœ)")
    parser.add_argument("--mode", default="realtime", choices=["realtime", "image"],
                       help="è¿è¡Œæ¨¡å¼ (realtime: å®æ—¶è§†é¢‘, image: å›¾ç‰‡å¤„ç†)")
    parser.add_argument("--img_path", default="./data/input/apple.png", type=str,
                       help="å›¾ç‰‡è·¯å¾„(ä»…imageæ¨¡å¼éœ€è¦)")
    
    args = parser.parse_args()
    
    if args.demo:
        run_demo_mode()
    else:
        if args.mode == "realtime":
            system = GestureFilterSystem()
            system.run()
        elif args.mode == "image":
            if not os.path.exists(args.img_path):
                print(f"âœ— å›¾ç‰‡ä¸å­˜åœ¨: {args.img_path}")
                return
            frame = cv2.imread(args.img_path)
            system = GestureFilterSystem()
            # original:åŸå›¾ï¼›histogram_equalization:ç›´æ–¹å›¾å‡è¡¡åŒ–ï¼›flowing_years:æµå¹´ç‰¹æ•ˆï¼›grayscale:ç°åº¦ç‰¹æ•ˆï¼›sepia:æ€€æ—§ç‰¹æ•ˆ
            processed_frame = system.image_filter.apply_filter(frame.copy(), "grayscale")
            # ä¿å­˜ç»“æœ
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"./data/output/photo_{timestamp}_grayscale.jpg"
            cv2.imwrite(filename, processed_frame)
            cv2.imshow("Gesture-based Image Filter System - Image Mode", processed_frame)
            print("æŒ‰ä»»æ„é”®å…³é—­å›¾ç‰‡çª—å£...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()


if __name__ == "__main__":
    main()
